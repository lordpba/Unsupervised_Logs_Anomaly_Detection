{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerie che servono, quelle che non sono installate si installano con %pip install nome_lib\n",
    "# ovviamente solo la prima volta, poi non serve più\n",
    "%pip install sentence-transformers \n",
    "%pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install xlsxwriter\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carichiamo le librerie necessarie\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "# eliminiamo i warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carichiamo dataset, possiamo caricare direttamente quello dettagliato generato da preparatore_DB\n",
    "# il percorso è relativo a questo file\n",
    "\n",
    "df = pd.read_csv(r'filecsv', sep=';', encoding='latin-1')\n",
    "# convertiamo tutti i nan in non definito (sono i gruppi non definiti)\n",
    "df = df.fillna('ND')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poiche' tutto il procedimento sara' molto pesante, cerchiamo di levare le colonne che non ci interessano\n",
    "# leviamo le colonne Descr Azienda Assegnazione, Descr Stab Assegnazione\n",
    "#df = df.drop(['Descr Azienda Assegnazione', 'Descr Stab Assegnazione'], axis=1)\n",
    "df = df.drop(['Descr Azienda Assegnazione'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abbiamo GPU con supporto CUDA?\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        device = torch.device(f\"cuda:{i}\")\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facciamo un embeddings con algoritmo BERT e modelli preaddestrati:\n",
    "# https://www.sbert.net/docs/pretrained_models.html\n",
    "# all-MiniLM-L6-v2 <--- veloce e valido\n",
    "# all-mpnet-base-v2 <--- lento ma piu' accurato\n",
    "\n",
    "modelST = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(modelST, device=device) \n",
    "\n",
    "# creiamo una funzione che ci permette di fare l'embeddings (batch_size dipende da quanta RAM abbiamo)\n",
    "def bert_embeddings(text):\n",
    "    return model.encode(text, device = device, batch_size=64, normalize_embeddings=True) #normalize_embeddings – If set to true, returned vectors will have length 1. In that case, the faster dot-product (util.dot_score) instead of cosine similarity can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI INTERO DATASET (fattibile solo se GPU con supporto CUDA presente e CPU multicore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facciamo embedding con BERT della colonna 'Activity' del dataset 'df'\n",
    "# attenzione, molto lungo, anche alcune ore, necessaria la GPU\n",
    "# se già fatto e salvato, saltare e andare al punto in cui lo si carica\n",
    "\n",
    "df['BERT_Embedding'] = df['Activity'].apply(bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memorizziamo l'embedding fatto salvandolo su disco, in seguito possiamo ricaricarlo da qui \n",
    "# (se salviamo/carichiamo l'emebdding come semplice file Excel/csv non sempre è corretto)\n",
    "\n",
    "embeddings = model.encode(df['Activity'])\n",
    "#Store sentences & embeddings on disc\n",
    "with open('embeddings.pkl', \"wb\") as fOut:\n",
    "    pickle.dump({'sentences': df['Activity'], 'embeddings': df['BERT_Embedding']}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carichiamo l'embedding se lo abbiamo già calcolato e salvato precedentemente\n",
    "# in modo da non doverlo ricalcolare\n",
    "\n",
    "#Load sentences & embeddings from disc\n",
    "with open('embeddings.pkl', \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data['sentences']\n",
    "    df['BERT_Embedding'] = stored_data['embeddings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlliamo dataset se e' tutto a posto\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troviamo la media degli embeddings ottimizzato per multithread\n",
    "import concurrent.futures\n",
    "\n",
    "def calculate_mean_embedding(df):\n",
    "    return np.mean(df['BERT_Embedding'])\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(calculate_mean_embedding, df)\n",
    "    embedding_avg = future.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the anomaly score for each SQL string related to embedding_avg\n",
    "print('Calcolo score di anomalia...')\n",
    "scores = np.dot(df['BERT_Embedding'].tolist(), embedding_avg)\n",
    "# convertiamo i valori ottenuti in numeri interi ad una sola cifra\n",
    "scores_abs = [int(score*10) for score in scores]\n",
    "# aggiungiamo la colonna con i punteggi\n",
    "df['Dataset_Anomaly'] = scores_abs\n",
    "# stampa quanti valori ci sono uguali a 1\n",
    "print('Numero di SQL con Dataset_Anomaly 1: ', len(df[df['Dataset_Anomaly'] == 1]))\n",
    "# stampa quanti valori ci sono uguali a 2\n",
    "print('Numero di SQL con Dataset_Anomaly 2: ', len(df[df['Dataset_Anomaly'] == 2]))\n",
    "# stampa quanti valori ci sono uguali a 3\n",
    "print('Numero di SQL con Dataset_Anomaly 3: ', len(df[df['Dataset_Anomaly'] == 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salviamo i dati in file excel per test\n",
    "#df.to_excel('reports/test.xlsx', index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI PER GRUPPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = df['Descr Artle Assegnazione'].unique()\n",
    "#group_list = group_list[:3] # facciamo test solo sui primi 3\n",
    "print('numero di gruppi da analizzare:', len(group_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### routine per gruppo ####\n",
    "output_file = open('reports/report_gruppi.txt', 'w')\n",
    "\n",
    "for group in group_list:\n",
    "    # Crea una cartella con il nome dell'utente se non esiste già\n",
    "    group_folder = os.path.join('reports', 'gruppi', str(group))\n",
    "    if not os.path.exists(group_folder):\n",
    "        os.makedirs(group_folder)\n",
    "\n",
    "\n",
    "    print('In elaborazione: ', group)\n",
    "    output_file.write('In elaborazione: ' + group + '\\n')\n",
    "    #lunghezza del gruppo\n",
    "    print('Numero di SQL: ', len(df[df['Descr Artle Assegnazione'] == group]))\n",
    "    output_file.write('Numero di SQL: ' + str(len(df[df['Descr Artle Assegnazione'] == group])) + '\\n')\n",
    "    # creo un dataframe per ogni gruppo\n",
    "    df_group = df[df['Descr Artle Assegnazione'] == group]\n",
    "    # reset index\n",
    "    df_group.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # facciamo embedding delle 'Activity' (disattivato, usiamo quello del dataset intero)\n",
    "    #print('BERT embedding delle SQL...')\n",
    "    #df_group['bert_embedding'] = df_group['Activity'].apply(bert_embeddings)\n",
    "\n",
    "    # troviamo la media degli embeddings, funzione molto veloce da generalizzare\n",
    "    print('Calcolo media degli embeddings...')\n",
    "    def calculate_mean_embedding(df_group):\n",
    "        return np.mean(df_group['BERT_Embedding'])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future = executor.submit(calculate_mean_embedding, df_group)\n",
    "        embedding_avg = future.result()\n",
    "    #embedding_avg = np.mean(df_group['BERT_Embedding']) #molto lento\n",
    "\n",
    "    # Calculate the anomaly score for each SQL string related to embedding_avg\n",
    "    print('Calcolo score di anomalia...')\n",
    "    scores = np.dot(df_group['BERT_Embedding'].tolist(), embedding_avg)\n",
    "    # convertiamo i valori ottenuti in numeri interi ad una sola cifra\n",
    "    scores_abs = [int(score*10) for score in scores]\n",
    "\n",
    "    # aggiungiamo la colonna con i punteggi\n",
    "    df_group['Group_Anomaly'] = scores_abs\n",
    "    \n",
    "    # stampa quanti valori ci sono uguali a 1\n",
    "    print('Numero di SQL con Group_Anomaly 1: ', len(df_group[df_group['Group_Anomaly'] == 1]))\n",
    "    output_file.write('Numero di SQL con Group_Anomaly 1: ' + str(len(df_group[df_group['Group_Anomaly'] == 1])) + '\\n')\n",
    "    # stampa quanti valori ci sono uguali a 2\n",
    "    print('Numero di SQL con Group_Anomaly 2: ', len(df_group[df_group['Group_Anomaly'] == 2]))\n",
    "    output_file.write('Numero di SQL con Group_Anomaly 2: ' + str(len(df_group[df_group['Group_Anomaly'] == 2])) + '\\n')\n",
    "    # stampa quanti valori ci sono uguali a 3\n",
    "    print('Numero di SQL con Group_Anomaly 3: ', len(df_group[df_group['Group_Anomaly'] == 3]))\n",
    "    output_file.write('Numero di SQL con Group_Anomaly 3: ' + str(len(df_group[df_group['Group_Anomaly'] == 3])) + '\\n')\n",
    "\n",
    "    # salviamo il dataframe\n",
    "    print('Salvataggio in corso...')\n",
    "    df_group.to_excel('reports/gruppi/' + str(group) + '/BERT_Embeddings_Score_%s.xlsx' %(group), index=False, engine='xlsxwriter')\n",
    "    print('Excel salvato consuccesso! \\n')\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI SU UTENTE SINGOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facciamo la stessa routine di sopra ma per utente\n",
    "user_list = list(df['User'].unique())\n",
    "#user_list = user_list[:20] # selezionare quanti utenti analizzare ad es: i primi 20\n",
    "print('numero di utenti da analizzare:', len(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### routine per utente ####\n",
    "\n",
    "output_file = open('reports/report_utenti.txt', 'w')\n",
    "\n",
    "for user in user_list:\n",
    "    \n",
    "    # Crea una cartella con il nome dell'utente se non esiste già\n",
    "    user_folder = os.path.join('reports', 'utenti', str(user))\n",
    "    if not os.path.exists(user_folder):\n",
    "        os.makedirs(user_folder)\n",
    "\n",
    "    print('In elaborazione: ', user)\n",
    "    output_file.write('In elaborazione: ' + user + '\\n')\n",
    "\n",
    "    # lunghezza dell'utente\n",
    "    print('Stringhe SQL totali: ', len(df[df['User'] == user]))\n",
    "    output_file.write('Stringhe SQL totali: ' + str(len(df[df['User'] == user])) + '\\n')\n",
    "    # creo un dataframe per ogni utente\n",
    "    df_user = df[df['User'] == user]\n",
    "    # reset index\n",
    "    df_user.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # facciamo embedding delle 'Activity'\n",
    "    #print('BERT embedding delle SQL...')\n",
    "    #df_user['bert_embedding'] = df_user['Activity'].apply(bert_embeddings)\n",
    "\n",
    "    # troviamo la media degli embeddings, funzione molto veloce da generalizzare\n",
    "    print('Calcolo media degli embeddings...')\n",
    "    def calculate_mean_embedding(df_user):\n",
    "        return np.mean(df_user['BERT_Embedding'])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future = executor.submit(calculate_mean_embedding, df_user)\n",
    "        embedding_avg = future.result()\n",
    "    #embedding_avg =np.mean(df_user['bert_embedding'])\n",
    "\n",
    "    # Calculate the anomaly score for each SQL string related to embedding_avg\n",
    "    print('Calcolo score di anomalia...')\n",
    "    scores = np.dot(df_user['BERT_Embedding'].tolist(), embedding_avg)\n",
    "    # convertiamo i valori ottenuti in numeri interi ad una sola cifra\n",
    "    scores_abs = [int(score*10) for score in scores]\n",
    "    # aggiungiamo la colonna con i punteggi\n",
    "    df_user['User_Anomaly'] = scores_abs\n",
    "\n",
    "    print('Numero di SQL con User_Anomaly 1: ', len(df_user[df_user['User_Anomaly'] == 1]))\n",
    "    output_file.write('Numero di SQL con User_Anomaly 1: ' + str(len(df_user[df_user['User_Anomaly'] == 1])) + '\\n')\n",
    "    # stampa quanti valori ci sono uguali a 2\n",
    "    print('Numero di SQL con User_Anomaly 2: ', len(df_user[df_user['User_Anomaly'] == 2]))\n",
    "    output_file.write('Numero di SQL con User_Anomaly 2: ' + str(len(df_user[df_user['User_Anomaly'] == 2])) + '\\n')\n",
    "    # stampa quanti valori ci sono uguali a 3\n",
    "    print('Numero di SQL con User_Anomaly 3: ', len(df_user[df_user['User_Anomaly'] == 3]))\n",
    "    output_file.write('Numero di SQL con User_Anomaly 3: ' + str(len(df_user[df_user['User_Anomaly'] == 3])) + '\\n' + '\\n')\n",
    "    \n",
    "    # salviamo il dataframe\n",
    "    print('Salvataggio in corso...')        \n",
    "    # salviamo il file in un file Excel\n",
    "    excel_filename = 'BERT_Embeddings_Score_{}.xlsx'.format(user)\n",
    "    excel_path = os.path.join(user_folder, excel_filename)\n",
    "    df_user.to_excel(excel_path, index=False, engine='xlsxwriter')\n",
    "    print('Excel salvato consuccesso! \\n')\n",
    "\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

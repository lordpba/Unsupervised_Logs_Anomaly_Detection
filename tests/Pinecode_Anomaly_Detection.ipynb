{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1234a0a7-23ec-4003-9fff-489ad3539ab2",
   "metadata": {},
   "source": [
    "# Pinecode - Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72224b89",
   "metadata": {},
   "source": [
    "### Import the Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7cebea-da30-4144-a980-19ffeb036147",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1048460f-d754-4560-bf64-8181c57a21cb",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, util\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "#from DLAIUtils import Utils\n",
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6bd87",
   "metadata": {},
   "source": [
    "### Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db99c27-9ab4-4eb3-962b-8bebcce499ae",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "INDEX_NAME = 'dl-ai'\n",
    "\n",
    "pinecone = Pinecone(api_key='PineconeAPIKey')\n",
    "\n",
    "# if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "#   pinecone.delete_index(INDEX_NAME)\n",
    "# pinecone.create_index(name=INDEX_NAME, dimension=256, metric='cosine',\n",
    "#   spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n",
    "# index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01176a02",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "**Note:** To access the dataset outside of this course, just copy the following three lines of code and run it (remember to uncomment them first before executing):\n",
    "\n",
    "#!wget -q --show-progress -O training.tar.zip \"https://www.dropbox.com/scl/fi/rihfngx4ju5pzjzjj7u9z/lesson6.tar.zip?rlkey=rct9a9bo8euqgshrk8wiq2orh&dl=1\"\n",
    "\n",
    "#!tar -xzvf training.tar.zip\n",
    "\n",
    "#!tar -xzvf lesson6.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6d0706-866a-4eaa-b957-3044badcd3e2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0]\n",
      "Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 type 3, code 0, by access-group \"acl_dmz\" [0xe3aab522, 0x0]\n",
      "Apr 15 2014 09:34:34 EDT: %ASA-session-5-106100: access-list acl_in permitted tcp inside/10.1.2.16(2241) -> outside/192.0.0.89(2000) hit-cnt 1 first hit [0x71a87d94, 0x0]\n",
      "Apr 24 2013 16:00:28 INT-FW01 : %ASA-6-106100: access-list inside denied udp inside/172.29.2.101(1039) -> outside/192.0.2.10(53) hit-cnt 1 first hit [0xd820e56a, 0x0]\n",
      "Apr 24 2013 16:00:27 INT-FW01 : %ASA-6-106100: access-list inside permitted udp inside/172.29.2.3(1065) -> outside/192.0.2.57(53) hit-cnt 144 300-second interval [0xe982c7a4, 0x0]\n"
     ]
    }
   ],
   "source": [
    "!head -5 sample.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09f94c0-41e3-40f7-a0f8-07dfb46be970",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ 1.0\n",
      "Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 type 3, code 0, by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ 0.9\n",
      "Apr 15 2014 09:34:34 EDT: %ASA-session-5-106100: access-list acl_in permitted tcp inside/10.1.2.16(2241) -> outside/192.0.0.89(2000) hit-cnt 1 first hit [0x71a87d94, 0x0] ^ Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ 0.8\n",
      "Apr 24 2013 16:00:28 INT-FW01 : %ASA-6-106100: access-list inside denied udp inside/172.29.2.101(1039) -> outside/192.0.2.10(53) hit-cnt 1 first hit [0xd820e56a, 0x0] ^ Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ 0.7\n",
      "Apr 24 2013 16:00:27 INT-FW01 : %ASA-6-106100: access-list inside permitted udp inside/172.29.2.3(1065) -> outside/192.0.2.57(53) hit-cnt 144 300-second interval [0xe982c7a4, 0x0] ^ Apr 15 2013 09:36:50: %ASA-4-106023: Deny tcp src dmz:10.1.2.30/63016 dst outside:192.0.0.8/53 by access-group \"acl_dmz\" [0xe3aab522, 0x0] ^ 0.7\n"
     ]
    }
   ],
   "source": [
    "!head -5 training.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5ac36",
   "metadata": {},
   "source": [
    "### Check cuda and Setup the Model\n",
    "\n",
    "We are using *bert-base-uncased* sentence-transformers model that maps sentences to a 256 dimensional dense vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed53bf9",
   "metadata": {
    "height": 147
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=768)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=256, activation_function=nn.Tanh())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model], device=device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ff493",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff162cdf-8c6d-4760-b21f-489e242c7eed",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "with open('training.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            a, b, label = line.split('^')\n",
    "            train_examples.append(InputExample(texts=[a, b], label=float(label)))\n",
    "\n",
    "#Define dataset, the dataloader and the training loss\n",
    "warmup_steps=100\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b725f3-ef8c-4f3c-93bd-6ab2812f654c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff1d7; padding:15px; \"> <b>(Note: <code>load_pretrained_model = True</code>):</b> We've saved the trained model and are loading it here for speedier results, allowing you to observe the outcomes faster. Once you've done an initial run, you may set <code>load_pretrained_model</code> to <code>False</code> to train the model yourself. This can take some time to finsih, depending the value you set for the <code>epochs</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3190a653-97f7-4684-8b8e-063a8b7ab678",
   "metadata": {
    "height": 302
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     trained_model_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.log\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sentence_transformers/fit_mixin.py:261\u001b[0m, in \u001b[0;36mFitMixin.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    259\u001b[0m     texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_texts\n\u001b[1;32m    260\u001b[0m     labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_labels\n\u001b[0;32m--> 261\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: text \u001b[38;5;28;01mfor\u001b[39;00m idx, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtexts))})\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Add label column, unless all labels are 0 (the default value for `labels` in InputExample)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_label_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datasets import Dataset\n",
    "\n",
    "load_pretrained_model = False\n",
    "if load_pretrained_model:\n",
    "    trained_model_file = open('./data/pretrained_model', 'rb')    \n",
    "    db = pickle.load(trained_model_file)\n",
    "    trained_model_file.close()\n",
    "else:\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=16, warmup_steps=100)\n",
    "\n",
    "samples = []\n",
    "with open('sample.log', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            #emb = model.encode([line])\n",
    "            samples.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216063b",
   "metadata": {},
   "source": [
    "### Create Embeddings and Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7c4f83b-c265-4f09-bcd4-7f82863c762b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m emb \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[43msamples\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "emb = model.encode(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b699c-9492-4a9c-9dfb-966345d59741",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prepped = []\n",
    "for i in tqdm(range(len(samples))):\n",
    "  v = {'id':f'{i}', 'values':emb[i].tolist(), 'metadata':{'log':samples[i]}}\n",
    "  prepped.append(v)\n",
    "index.upsert(prepped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92e64d",
   "metadata": {},
   "source": [
    "### Find the Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3d0c4-3f46-4651-8eec-427599fd73a9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "good_log_line = samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b3507-3648-4a2d-b420-3b92672c3960",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(good_log_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f161a-af9b-4c64-9ee1-4073f4fdfecf",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "while len(results)==0:  # After the upserts, it might take a few seconds for index to be ready for query.  \n",
    "    time.sleep(2)       # If results is empty we try again two seconds later.\n",
    "    queried = index.query(\n",
    "        vector=emb[0].tolist(),\n",
    "        include_metadata=True,\n",
    "        top_k=100\n",
    "    )\n",
    "    results = queried['matches']\n",
    "    print(\".:. \",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11263342-1dd5-49d7-b083-a9cd8487bfa5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for i in range(0,10) :\n",
    "  print(f\"{round(results[i]['score'], 4)}\\t{results[i]['metadata']['log']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae3f7e-44c8-4885-a086-1e3a3cdf5505",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "last_element = len(results) -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14c27f-7ec3-4643-89a1-c549f4d4e58a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(f\"{round(results[last_element]['score'], 4)}\\t{results[last_element]['metadata']['log']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
